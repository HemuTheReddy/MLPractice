# -*- coding: utf-8 -*-
"""03_Intro-CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ucdZdGTHHOMm4TZwecy01pONqvyhCzpd

# Introduction to Convolutional Neural Networks and Computer Vision with tensorflow

Computer vision is the practice of writing algorithms which can discover patterns in visual data. Such as the camera of a self-driving car recognizing the car in front.

## Get the data
"""

import zipfile

!wget https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip

# Unzip the downloaded file
zip_ref=zipfile.ZipFile("pizza_steak.zip")
zip_ref.extractall()
zip_ref.close()

"""## Inspect the data (become on with it)

A very crucial step at the beginning of any machine learning proejct is becoming one with the data.

And for a computer vision project, this usually means visualizing invidual samples of the data
"""

!ls pizza_steak

!ls pizza_steak/train/

!ls pizza_steak/train/steak

import os

# Walk through the pizza steak directory and list number of files
for dirpath, dirnames, filenames in os.walk("pizza_steak"):
  print(f"There are {len(dirnames)} directoreis and {len(filenames)} images in '{dirpath}.")

# Another way to find out how many images are in a file
num_steak_images_train=len(os.listdir('pizza_steak/train/steak'))

num_steak_images_train

"""To visualize our images, first let's get the class names programmatically."""

# Get the class names programmatically
import pathlib
import numpy as np
data_dir = pathlib.Path("pizza_steak/train")
class_names = np.array(sorted([item.name for item in data_dir.glob("*")])) #Created a list of class names from the subdirectories
print(class_names)

# Let's visualize our images
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import random

def view_random_image(target_dir, target_class):
  # Setup the target directory (we'll view images from here)
  target_folder = target_dir+target_class

  # Get a random image path
  random_image = random.sample(os.listdir(target_folder), 1)

  # Read in the image and plot using matplotlib
  img = mpimg.imread(target_folder + "/" + random_image[0])
  plt.imshow(img)
  plt.title(target_class)
  plt.axis("off");

  print(f'Image shape: {img.shape}') #show the shape of the image
  return img

# View a random image from the training dataset

img = view_random_image(target_dir="pizza_steak/train/",
                        target_class="pizza")

import tensorflow as tf
tf.constant(img)

# View the image shape
img.shape #returns width, height, color channels

# Get all the pixel values between 0 and 1
img/255.

"""## An end-to-end example

Let's build a convolutional neural network to find patterns in our images, more specifically, we need a way to:

* Load our images
* Preprocess our images
* Build our CNN to find patterns in our images
* Compile our CNN
* Fit the CNN to our training data
"""

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# set the seed
tf.random.set_seed(42)

#preprocess the data(get all of the pixel values between 0 and 1, also called scaling/normalization)
train_datagen = ImageDataGenerator(rescale=1./255)
valid_datagen = ImageDataGenerator(rescale=1./255)

# Setup paths to our data directories
train_dir = "/content/pizza_steak/train"
test_dir = "pizza_steak/test"
# import data from directories and turn it into batches
train_data = train_datagen.flow_from_directory(directory = train_dir,
                                               batch_size=32,
                                               target_size=(224, 224),
                                               class_mode="binary",
                                               seed=42)
valid_data = valid_datagen.flow_from_directory(directory=test_dir,
                                               batch_size=32,
                                               target_size=(224, 224),
                                               class_mode ="binary",
                                               seed=42)
# Build a CNN model (same as Tiny VGG on the CNN explainer website)

model_1 = tf.keras.Sequential([
    tf.keras.layers.Conv2D(filters=10,
                           kernel_size=3,
                           activation="relu",
                           input_shape=(224,224,3)),
    tf.keras.layers.Conv2D(10, 3, activation = "relu"),
    tf.keras.layers.MaxPool2D(pool_size=2,
                              padding="valid"),
    tf.keras.layers.Conv2D(10, 3, activation="relu"),
    tf.keras.layers.Conv2D(10, 3, activation = "relu"),
    tf.keras.layers.MaxPool2D(2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(1, activation ="sigmoid")
])

# Compile our CNN
model_1.compile(loss="binary_crossentropy",
                optimizer=tf.keras.optimizers.Adam(),
                metrics=["accuracy"])

# fit the model
history_1 = model_1.fit(train_data,
                        epochs = 5,
                        steps_per_epoch=len(train_data),
                        validation_data = valid_data,
                        validation_steps=len(valid_data))

model_1.summary()

"""## Using the same model as before

Let's replicate the model we've built in a previous section to see if it works with our image data.

The model we're building is from the TensorFlow playground
"""

# Set random seed
tf.random.set_seed(42)

# Create a model to replicate the Tensorflow Playground model

model_2 = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(224, 224, 3)),
    tf.keras.layers.Dense(4, activation="relu"),
    tf.keras.layers.Dense(4, activation ="relu"),
    tf.keras.layers.Dense(1, activation="sigmoid")
])

# Compile the model

model_2.compile(loss="binary_crossentropy",
                optimizer=tf.keras.optimizers.Adam(),
                metrics=["accuracy"])

history_2 = model_2.fit(train_data, epochs=5,
                        steps_per_epoch=len(train_data),
                        validation_data=valid_data,
                        validation_steps=len(valid_data))

model_2.summary()

tf.random.set_seed(42)

model_3 = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(224, 224, 3)),
    tf.keras.layers.Dense(100, activation="relu"),
    tf.keras.layers.Dense(100, activation="relu"),
    tf.keras.layers.Dense(100, activation="relu"),
    tf.keras.layers.Dense(1, activation="sigmoid")
])

model_3.compile(loss="binary_crossentropy",
                optimizer=tf.keras.optimizers.Adam(),
                metrics=["accuracy"])

history_3 = model_3.fit(train_data, epochs = 5, steps_per_epoch = len(train_data),
                        validation_data =valid_data, validation_steps = len(valid_data))

model_3.summary()

"""## Binary Classification: Let's break it down

1. Become one with the data (visualize)
2. Preprocess the data (scaling, prepared it for model)
3. Created a model
4. Fit the model
5. Evalutate the model
6. Adjust parameters and improve the model
7. Repeat until satisfied(experiment a lot)

### 1. Become one with the data
"""

# Visualize the data
plt.figure()
plt.subplot(1, 2, 1)
steak_img=view_random_image("pizza_steak/train/", "steak")
plt.subplot(1, 2, 2)
pizza_img = view_random_image("pizza_steak/train/", "pizza")

train_dir = "pizza_steak/train/"
test_dir = "pizza_steak/test/"

"""### 2. Preprocess the data"""

# Create train and test data generators and rescale the data
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1/255.)
test_datagen = ImageDataGenerator(rescale=1/255.)

# Load in our image data from directories and turn them into batches

train_data = train_datagen.flow_from_directory(directory=train_dir, #Target directory of images
                                               target_size=(224,224), #target size of images (height, width)
                                               class_mode="binary", # type of data you're working with
                                               batch_size=32) #size of minibatches to load data into
test_data = test_datagen.flow_from_directory(directory=test_dir,
                                             target_size=(224,224),
                                             class_mode="binary",
                                             batch_size=32)

# Get a sample of a train data batch

images, labels = train_data.next() # get the "next" batch of images/labels in train data

len(images), len(labels)

# How many batches are there

len(train_data)

# Get the first two images
images[:2], images[0].shape

# View the first batch of labels

labels

"""### 3. Create a CNN model (start with a baseline)

A baseline is a relatively simple model or existing result that you setup when beginning a machine learning experiment
and then as you keep experimenting, you try and beat the baseline

**Note:** In deep learning, there is almost an infinite amount of architechtures you could create. So one of the best ways to get started is to start with something simple and see if it works on your data, and then introduce complexity as required (e.g., look at which current model is performing best in the field for your problem)
"""

# Make the creating of our model a little easier
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation
from tensorflow.keras import Sequential

# Create the model (this will be our baseline, a 3-layer convolutional neural network)

model_4 = Sequential([
    Conv2D(filters=10,
           kernel_size=3,
           strides=1,
           padding="valid",
           activation="relu",
           input_shape=(224,224, 3)),
    Conv2D(10, 3, activation="relu"),
    Conv2D(10, 3, activation="relu"),
    Flatten(),
    Dense(1, activation="sigmoid") #output layer
])

model_4.summary()

"""### 4. Compile the model"""

len(train_data), len(test_data)

model_4.compile(loss="binary_crossentropy",
                optimizer=Adam(),
                metrics=["accuracy"])

"""### 5. Fit the model"""

history_4 = model_4.fit(train_data,
                      epochs = 5,
                      steps_per_epoch=len(train_data),
                      validation_data=test_data,
                      validation_steps=len(test_data))

"""### 5. Evaluating our model

It looks like our model is learning something, let's evaluate it.
"""

#Let's plot the training curves
import pandas as pd
pd.DataFrame(history_4.history).plot(figsize=(10,7))

# Plot the validation and training curves separately

def plot_loss_curves(history):
  """
  Return separate loss curves for training and validation metrics
  """
  loss= history.history["loss"]
  val_loss = history.history["val_loss"]
  accuracy = history.history["accuracy"]
  val_accuracy = history.history["val_accuracy"]
  epochs = range(len(history.history["loss"]))

  #plot loss
  plt.plot(epochs, loss, label="training_loss")
  plt.plot(epochs, val_loss, label="val_loss")
  plt.xlabel("epochs")
  plt.title("loss")
  plt.legend();
  #plot accuracy
  plt.figure()
  plt.plot(epochs, accuracy, label="training_accuracy")
  plt.plot(epochs, val_accuracy, label="val_accuracy")
  plt.xlabel("epochs")
  plt.title("accuracy")
  plt.legend();

"""**Note:** When a model's validation loss starts to increase, it's likely that the model is **overfitting** the training dataset. This means that it is learning the patterns in the training data set too well, thus the model's ability to generalize to unseen data will be diminished"""

# Check out the loss and accuracy of model 4

plot_loss_curves(history_4)

"""### 6. Adjust the model's parameters

Fitting a machine learning model comes in 3 steps:

0. Create a baseline
1. Beat the baseline by overfitting a label
2. Reduce overfitting

Ways to induce overfitting:

* Increase the number of conv layers
* Increase the number of conv filters
* Add another dense layer to the output of our flattened layer

Reduce overfitting:
* Add data augmentation
* Add regularization layers (such as MaxPool2D)
* Add more data...
"""

# create the model (this is going to be our new baseline)

model_5 =  Sequential([
    Conv2D(10, 3, activation="relu", input_shape=(224,224,3)),
    MaxPool2D(pool_size=2),
    Conv2D(10, 3, activation="relu"),
    MaxPool2D(),
    Conv2D(10, 3, activation = "relu"),
    MaxPool2D(),
    Flatten(),
    Dense(1, activation="sigmoid")
])

#compile the model
model_5.compile(loss="binary_crossentropy",
                optimizer=Adam(),
                metrics=["accuracy"])

history_5 = model_5.fit(train_data,
                        epochs = 5,
                        steps_per_epoch=len(train_data),
                        validation_data=test_data,
                        validation_steps=len(test_data))

model_5.summary()

#plot loss curves
plot_loss_curves(history_5)

"""### Opening our bag of tricks and finding data augmentation"""

# Create ImageDataGenerator training instance with data augmentation
train_datagen_augmented = ImageDataGenerator(rescale=1/255.,
                                             rotation_range=0.2,
                                             shear_range=0.2,
                                             zoom_range=0.2,
                                             width_shift_range=0.2,
                                             height_shift_range=0.3,
                                             horizontal_flip=True)
# Create ImageDataGenerator without data augmentation
train_datagen = ImageDataGenerator(rescale=1/255.)

# Create ImageGenerator without data augmentation for test data set
test_datagen = ImageDataGenerator(rescale=1/255.)

# Import data and augment it from training directory
print("Augmented training data")
train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,
                                                               target_size=(224,224),
                                                               batch_size=32,
                                                               class_mode="binary",
                                                               shuffle=False) # for demonstration purposes only
# create non augmented train batches
print("Non-augmented training data")
train_data = train_datagen.flow_from_directory(train_dir,
                                                  target_size=(224,224),
                                                  batch_size=32,
                                                  class_mode="binary",
                                                  shuffle=False)
# create non-augmented test data batches
print("non-augmented test data")
test_data = test_datagen.flow_from_directory(test_dir,
                                             target_size=(224,224),
                                             batch_size=32,
                                             class_mode="binary")

# Get sample augmented data batches
images, labels = train_data.next()
augmented_images, augmented_labels = train_data_augmented.next()

# Show the original image and the augmented image
import random
randomN = random.randint(0, 32) #our batch sizes are 32...
print(f"showing image number: {randomN}")
plt.imshow(images[randomN])
plt.title("original image")
plt.axis(False)
plt.figure()
plt.imshow(augmented_images[randomN])
plt.title(f'Augmented image')
plt.axis(False);

"""Now we've seen what augmented training data looks like, let's build a model and see how it learns on augmented data"""

# Create a model (same as model 5)

model_6 = Sequential([
    Conv2D(10, 3, activation="relu", input_shape=(224, 224, 3)),
    MaxPool2D(pool_size=2),
    Conv2D(10, 3, activation="relu"),
    MaxPool2D(),
    Conv2D(10, 3, activation="relu"),
    MaxPool2D(),
    Flatten(),
    Dense(1, activation="sigmoid")
])

model_6.compile(loss="binary_crossentropy",
                optimizer=Adam(),
                metrics=["accuracy"])
history_6 = model_6.fit(train_data_augmented, #fitting model_6 on augmented training data
                        epochs = 5,
                        steps_per_epoch = len(train_data_augmented),
                        validation_data = test_data,
                        validation_steps = len(test_data))

# Check our models training curves

plot_loss_curves(history_6)

# shuffled data

train_data_augmented_shuffled = train_datagen_augmented.flow_from_directory(train_dir,
                                                                            target_size=(224, 224),
                                                                            class_mode="binary",
                                                                            shuffle=True)

# create model

model_7 = Sequential([
    Conv2D(10, 3, activation = "relu", input_shape=(224, 224, 3)),
    MaxPool2D(),
    Conv2D(10, 3, activation="relu"),
    MaxPool2D(),
    Conv2D(10, 3, activation="relu"),
    MaxPool2D(),
    Flatten(),
    Dense(1, activation="sigmoid")
])
model_7.compile(loss="binary_crossentropy",
                optimizer=Adam(),
                metrics=["accuracy"])
history_7 = model_7.fit(train_data_augmented_shuffled,
                        epochs = 5,
                        steps_per_epoch= len(train_data_augmented_shuffled),
                        validation_data = test_data,
                        validation_steps = len(test_data))

plot_loss_curves(history_7)

"""### 7. Repeat until satisfied

Since we beat baseline, to improve:

* Increase model layers
* Increase filters in each conv layer
* Train for longer (more epochs)
* Find an ideal learning rate
* Get more data
* Use **transfer learning**

## Making a prediction with our trained model on our own custom data
"""

# Classes we're working with
print(class_names)

# View our example image
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-steak.jpeg
steak = mpimg.imread("03-steak.jpeg")

plt.imshow(steak)
plt.axis(False)

# check the shape of our image
steak.shape

# create a function to import an image and resize it to be able to be used with our model
def load_and_prep_image(filename, img_shape=224):
  """
  Reads an image from filename and turns it into a tensor and reshapes it
  to (img_shape, img_shape, color_channels).
  """
  # Read in the image
  img = tf.io.read_file(filename)
  # Decode the read file into a tensor
  img = tf.image.decode_image(img)
  #Resize the image
  img = tf.image.resize(img, size=[img_shape, img_shape])
  #Rescale the image (get all values between 0 and 1)
  img = img/255
  return img

#load in and preprocess our custom image

steak = load_and_prep_image("03-steak.jpeg")
steak

pred = model_7.predict(tf.expand_dims(steak, axis=0))
pred

#visualize image and model prediction

#remind ourselves of class names
class_names

# We can index the predicted class by rounding the prediction probability and indexing on class_names
pred_class=class_names[int(tf.round(pred))]
pred_class

def pred_and_plot(model, filename, class_names=class_names):
  """
  Imports an image located at filename, makes a prediction with model and
  plots the image with the predicted class as the title
  """
  #import target image and preprocess it
  img = load_and_prep_image(filename)

  # Make a prediction
  pred = model.predict(tf.expand_dims(img, axis=0))

  # Get the predicted class
  pred_class = class_names[int(tf.round(pred))]

  #Plot the image and predicted class
  plt.imshow(img)
  plt.title(f'prediction: {pred_class}')
  plt.axis(False)

#test model on custom image
pred_and_plot(model_7, "03-steak.jpeg")

!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-pizza-dad.jpeg

pred_and_plot(model_7, "03-pizza-dad.jpeg")

!wget https://hips.hearstapps.com/hmg-prod/images/how-to-grill-steak-1653399983.jpeg?crop=1.00xw:0.501xh;0,0.392xh&resize=1200:*

pred_and_plot(model_7, "how-to-grill-steak-1653399983.jpeg?crop=1.00xw:0.501xh")

"""## Multi-Class Image Classification

We've just been to a bunch of the following steps with a binary classification problem (pizza vs. steak), now we're going to step things up a notch with 10 classes of food (multi-class classification).

1. Become one with the data
2. Preprocess the data (get it ready for a model)
3. Create a model (start with a baseline)
4. Fit the model (overfit to make sure it works)
5. Evaluate the model
6. Adjust different hyperparameters and improve model (beat baseline/reduce overfitting)
7. Repeat until satisfied

## 1. Import and become one with the data
"""

import zipfile

!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip

#Unzip data

zip_ref = zipfile.ZipFile("10_food_classes_all_data.zip")
zip_ref.extractall()
zip_ref.close()

import os

#Walk through 10 classes of food image data
for dirpath, dirnames, filenames in os.walk("10_food_classes_all_data"):
  print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.")

#Setup the train and test directories
train_dir = "10_food_classes_all_data/train/"
test_dir = "10_food_classes_all_data/test/"

#Let's get the class names
import pathlib
import numpy as np
data_dir = pathlib.Path(train_dir)
class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))
print(class_names)

#Visualize
img = view_random_image(target_dir=train_dir,
                        target_class=random.choice(class_names))

"""### 2. Preprocess the data(prepare it for a model)"""



from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(1/255.)
test_datagen = ImageDataGenerator(1/255.)

train_data = train_datagen.flow_from_directory(directory = train_dir,
                                               target_size=(224,224),
                                               class_mode='categorical',
                                               batch_size=32)
test_data = test_datagen.flow_from_directory(directory = test_dir,
                                             target_size=(224,224),
                                             class_mode='categorical',
                                             batch_size=32)

images, labels = train_data.next()

"""### 3. Create a model (start with a baseline)"""

import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPool2D, Activation

# create mode

model_8 = Sequential([
    Conv2D(10, 3, input_shape=(224,224,3)),
    Activation(activation="relu"),
    Conv2D(10, 3),
    Activation(activation="relu"),
    MaxPool2D(),
    Conv2D(10, 3),
    Activation(activation="relu"),
    Conv2D(10, 3),
    Activation(activation="relu"),
    MaxPool2D(),
    Flatten(),
    Dense(10, activation="softmax")
])

# compile
model_8.compile(loss="categorical_crossentropy",
                optimizer=tf.keras.optimizers.Adam(),
                metrics=["accuracy"])

# fit
history_8 = model_8.fit(train_data,
            epochs = 5,
            steps_per_epoch = len(train_data),
            validation_data = test_data,
            validation_steps = len(test_data))

"""### 5. Evaluate the model"""

# Evaluate on the test data
model_8.evaluate(test_data)

# Check out the model's loss curve

plot_loss_curves(history_8)